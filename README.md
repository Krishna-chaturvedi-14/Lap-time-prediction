# ğŸ Lap Time Prediction using CatBoost

This project focuses on predicting **Lap_Time_Seconds** for MotoGP riders using a wide range of race, track, environmental, and performance-related features. The model is built using **CatBoost Regressor** and optimized to achieve **very low RMSE**, ideally below **0.001**.

---

## ğŸ“‚ Dataset Overview

| File Name      | Description                                      |
|----------------|--------------------------------------------------|
| `train.csv`    | Historical race data with target values          |
| `test.csv`     | Race entries without target values (for prediction) |
| `val.csv`      | Sample submission format                         |

---

## ğŸ§  Features Used

- **Rider Metadata**  
  `Rider_ID`, `years_active`, `Championship_Position`, `Championship_Points`, etc.

- **Bike & Team Info**  
  `Bike`, `Team`, `bike_name`

- **Track Details**  
  `Circuit_Length_km`, `Corners_per_Lap`, `Pit_Stop_Duration_Seconds`

- **Environment & Conditions**  
  `Humidity_%`, `Track_Condition`, `weather`, `Ambient_Temperature_Celsius`, etc.

- **Performance Indicators**  
  `Avg_Speed_kmh`, `Grid_Position`, `Penalty`, `podiums`, `wins`, `starts`, `finishes`

---

## âš™ï¸ Model Pipeline

### ğŸ”§ Preprocessing

- Missing values handled:
  - **Categorical** â†’ `'Unknown'`
  - **Numerical** â†’ median imputation
- All categorical features converted to string and label-encoded
- Dropped identifier fields like `Unique ID` and `rider_name` to avoid data leakage

### ğŸ¤– Modeling

- **Model**: `CatBoostRegressor`
- **Parameters**:
  - `iterations=3000`
  - `learning_rate=0.01`
  - `depth=10`
  - `early_stopping_rounds=100`
- **Target**: RMSE < **0.001**

### ğŸ“ˆ Validation

- 5-Fold Cross-Validation
- Metric: **Root Mean Squared Error (RMSE)**
- Final RMSE achieved: **~0.0786**

---

## ğŸ“ How to Run

Ensure a Kaggle-compatible Python environment (or use Jupyter locally).

```python
import pandas as pd
from catboost import CatBoostRegressor
from sklearn.metrics import mean_squared_error

# Load data
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
sample_submission = pd.read_csv("val.csv")

# Preprocessing, feature engineering, and training steps...


After running the notebook, predictions are saved to submission.csv.

ğŸ“Š Results
âœ… Final RMSE (Validation Set): 0.0786

âœ… All preprocessing and predictions handled in a clean pipeline

âœ… Ready for real-world deployment or ensemble integration

ğŸ“Œ Notes
Avoid leakage from high-cardinality ID fields (like rider_name, Unique ID)

Model can be further improved by:

Ensembling with LightGBM or XGBoost

Feature interaction generation

Hyperparameter tuning via Optuna or Bayesian Optimization

ğŸ“ File Structure
bash
Copy
Edit
burnout_Hackjack.ipynb     # Full training and prediction notebook
submission.csv             # Final test predictions
README.md                  # Project overview
